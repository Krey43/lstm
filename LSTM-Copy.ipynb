{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 27 days\n",
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 27 days\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debug = True # global var to control debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "\n",
    "import theano.tensor as TT\n",
    "\n",
    "from theano.tensor.shared_randomstreams import RandomStreams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# These are taken from https://github.com/mila-udem/blocks\n",
    "# \n",
    "\n",
    "class Constant():\n",
    "    \"\"\"Initialize parameters to a constant.\n",
    "    The constant may be a scalar or a :class:`~numpy.ndarray` of any shape\n",
    "    that is broadcastable with the requested parameter arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    constant : :class:`~numpy.ndarray`\n",
    "        The initialization value to use. Must be a scalar or an ndarray (or\n",
    "        compatible object, such as a nested list) that has a shape that is\n",
    "        broadcastable with any shape requested by `initialize`.\n",
    "    \"\"\"\n",
    "    def __init__(self, constant):\n",
    "        self._constant = numpy.asarray(constant)\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        dest = numpy.empty(shape, dtype=np.float32)\n",
    "        dest[...] = self._constant\n",
    "        return dest\n",
    "\n",
    "\n",
    "class IsotropicGaussian():\n",
    "    \"\"\"Initialize parameters from an isotropic Gaussian distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    std : float, optional\n",
    "        The standard deviation of the Gaussian distribution. Defaults to 1.\n",
    "    mean : float, optional\n",
    "        The mean of the Gaussian distribution. Defaults to 0\n",
    "    Notes\n",
    "    -----\n",
    "    Be careful: the standard deviation goes first and the mean goes\n",
    "    second!\n",
    "    \"\"\"\n",
    "    def __init__(self, std=1, mean=0):\n",
    "        self._mean = mean\n",
    "        self._std = std\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        m = rng.normal(self._mean, self._std, size=shape)\n",
    "        return m.astype(np.float32)\n",
    "\n",
    "\n",
    "class Uniform():\n",
    "    \"\"\"Initialize parameters from a uniform distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    mean : float, optional\n",
    "        The mean of the uniform distribution (i.e. the center of mass for\n",
    "        the density function); Defaults to 0.\n",
    "    width : float, optional\n",
    "        One way of specifying the range of the uniform distribution. The\n",
    "        support will be [mean - width/2, mean + width/2]. **Exactly one**\n",
    "        of `width` or `std` must be specified.\n",
    "    std : float, optional\n",
    "        An alternative method of specifying the range of the uniform\n",
    "        distribution. Chooses the width of the uniform such that random\n",
    "        variates will have a desired standard deviation. **Exactly one** of\n",
    "        `width` or `std` must be specified.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean=0., width=None, std=None):\n",
    "        if (width is not None) == (std is not None):\n",
    "            raise ValueError(\"must specify width or std, \"\n",
    "                             \"but not both\")\n",
    "        if std is not None:\n",
    "            # Variance of a uniform is 1/12 * width^2\n",
    "            self._width = numpy.sqrt(12) * std\n",
    "        else:\n",
    "            self._width = width\n",
    "        self._mean = mean\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        w = self._width / 2\n",
    "        m = rng.uniform(self._mean - w, self._mean + w, size=shape)\n",
    "        return m.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def default(var, val):\n",
    "    if var is None:\n",
    "        return val\n",
    "    else:\n",
    "        return var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM implementation in Theano\n",
    "\n",
    "Theano fully supports recurrent neural networks. One typically needs only to provide an implementation of a single step of the recurrency.\n",
    "\n",
    "Please read about the scan function which is used to implement the loops: http://deeplearning.net/software/theano/library/scan.html.\n",
    "\n",
    "**Attention**: through the code we will assume that the 0-th axis refers to time and that the 1-st axis refers to individual examples inside a minibatch. (This way in a C-major memory layout individual time steps occupy contiguous regions in memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Taken from https://github.com/vitruvianscience/OpenDeep/blob/master/opendeep/utils/activation.py\n",
    "    \n",
    "    See the Theano documentation.\n",
    "    Returns the row-wise softmax function of x.\n",
    "    In the case of 3D input, it returns the scan of softmax applied over the second two dimensions\n",
    "    (loops over first dimension).\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : 2D or 3D tensor\n",
    "        Symbolic 2D or 3D Tensor (or compatible).\n",
    "    Returns\n",
    "    -------\n",
    "    2D or 3D tensor\n",
    "        Row-wise softmax: softmax_{ij}(x) = exp(x_{ij})/sum_k(exp(x_{ik})) applied to `x`. Returns same shape as input.\n",
    "    \"\"\"\n",
    "    if x.ndim == 3:\n",
    "        cost, _ = theano.scan(fn=TT.nnet.softmax, sequences=x)\n",
    "        return cost\n",
    "    return TT.nnet.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self, rng=None):\n",
    "        if rng is None:\n",
    "            rng = numpy.random\n",
    "        self.rng = rng\n",
    "        self._parameters = []\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return self._parameters\n",
    "    \n",
    "    def add_param(self, name, shape, initializer, dtype='float32'):\n",
    "        param = theano.shared(numpy.zeros(\n",
    "            shape, dtype=dtype), name=name)\n",
    "        param.tag.initializer = initializer\n",
    "        self._parameters.append(param)\n",
    "        setattr(self, name, param)\n",
    "        \n",
    "    def initialize(self):\n",
    "        for p in self.parameters:\n",
    "            p.set_value(p.tag.initializer.generate(self.rng, \n",
    "                                                   p.get_value().shape))\n",
    "\n",
    "\n",
    "class RecurrentLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(RecurrentLayer, self).__init__(**kwargs)\n",
    "        self.initial_states = []\n",
    "    \n",
    "    def apply(self, X, **kwargs):\n",
    "        batch_size = X.shape[1]\n",
    "        outputs_info = []\n",
    "        for h in self.initial_states:\n",
    "            h0 = TT.repeat(h, batch_size, axis=0)\n",
    "            outputs_info.append(dict(initial=h0))\n",
    "        \n",
    "        #\n",
    "        # Scan in theano takes a function which performs a single step of the\n",
    "        # recurrent computation. Subclasses just need to provide the\n",
    "        # self.transition function.\n",
    "        #\n",
    "        scan_result, scan_updates = theano.scan(\n",
    "            self.transition,\n",
    "            sequences=X,\n",
    "            outputs_info=outputs_info,\n",
    "            **kwargs\n",
    "            )\n",
    "        # Note: this in general will not be the case and we will need to\n",
    "        # make sure that the updates are given to theano.function\n",
    "        assert not scan_updates\n",
    "        return scan_result\n",
    "\n",
    "\n",
    "class MergeInputHiddens(Layer):\n",
    "    \"\"\"\n",
    "    Merge two sequences - inputs and hidden states and produce an output.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim,\n",
    "                 weight_init=None, bias_init=None, \n",
    "                 **kwargs):\n",
    "        super(MergeInputHiddens, self).__init__(**kwargs)\n",
    "        weight_init = default(\n",
    "            weight_init, IsotropicGaussian(1.0/sqrt(in_dim)))\n",
    "        bias_init = default(\n",
    "            weight_init, Constant(0.))\n",
    "        \n",
    "        # Input to output\n",
    "        self.add_param('Wxo', (in_dim, out_dim), \n",
    "                       weight_init)\n",
    "        \n",
    "        # Hidden to output\n",
    "        self.add_param('Who', (hidden_dim, out_dim), \n",
    "                       weight_init)\n",
    "        \n",
    "        # Output bias\n",
    "        self.add_param('Bo', (out_dim,), \n",
    "                       bias_init)\n",
    "        \n",
    "    def apply(self, X, H):\n",
    "        # Get the shape\n",
    "        nsteps, bs, nin = X.shape\n",
    "        nhid = H.shape[2]\n",
    "        \n",
    "        # Note - we flatten the steps and batch size\n",
    "        # as the computation of outputs can be performed in \n",
    "        # parallel for all time steps.\n",
    "        \n",
    "        O = (X.reshape((nsteps*bs, nin)).dot(self.Wxo) + \n",
    "             H.reshape((nsteps*bs, nhid)).dot(self.Who) +\n",
    "             self.Bo)\n",
    "        return O.reshape((nsteps, bs, O.shape[1]))\n",
    "    \n",
    "class Chain(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Chain, self).__init__(**kwargs)\n",
    "        self.children = []\n",
    "        \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        ret = list(self._parameters)\n",
    "        for c in self.children:\n",
    "            ret.extend(c.parameters)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    \"\"\"\n",
    "    This class computes the updates to parameters using the RMSProp learning rule and adding weight decay.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, net_loss, parameters, inputs):\n",
    "        self.RMSProp_dec_rate = \\\n",
    "            theano.shared(np.array(0.9, dtype='float32'))\n",
    "        self.RMSProp_epsilon = \\\n",
    "            theano.shared(np.array(1e-5, dtype='float32'))\n",
    "        self.lrate = \\\n",
    "            theano.shared(np.array(1e-2, dtype='float32'))\n",
    "        self.max_grad_norm = \\\n",
    "            theano.shared(np.array(1., dtype='float32'))\n",
    "        self.wdec = \\\n",
    "            theano.shared(np.array(0., dtype='float32'))\n",
    "\n",
    "        theano.config.compute_test_value='off' # Turn off for gradient computation\n",
    "        \n",
    "        wdec_loss = 0\n",
    "        for p in parameters:\n",
    "            if p.name[0]=='W':\n",
    "                wdec_loss = wdec_loss + (p**2).sum()*self.wdec\n",
    "        \n",
    "        grads = theano.grad(net_loss + wdec_loss, parameters)\n",
    "        updates = []\n",
    "\n",
    "        grad_norm = 0.\n",
    "\n",
    "        for g in grads:\n",
    "            grad_norm = grad_norm + (g**2).sum()\n",
    "        \n",
    "\n",
    "        for g,p in zip(grads, parameters):\n",
    "            step = g\n",
    "            step = g / TT.maximum(1.0, grad_norm/self.max_grad_norm)\n",
    "            if 1:\n",
    "                g2 = theano.shared(p.get_value() * 0.,\n",
    "                                   name=p.name + '_g2')\n",
    "                g2_new = (self.RMSProp_dec_rate * g2 + \n",
    "                          (1.0 - self.RMSProp_dec_rate) * g**2)\n",
    "                updates.append((g2, g2_new))\n",
    "                step = step / TT.sqrt(g2_new + self.RMSProp_epsilon)\n",
    "\n",
    "            step = self.lrate * step\n",
    "            updates.append((p, p - step))\n",
    "\n",
    "        self.train_function = theano.function(inputs, \n",
    "                                              [net_loss, net_loss + wdec_loss, grad_norm], \n",
    "                                              updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM_RNN(RecurrentLayer):\n",
    "    \"\"\"\n",
    "    Implementation follows Alex Graves, Abdel-rahman Mohamed and Geoffrey Hinton\n",
    "    \"SPEECH RECOGNITION WITH DEEP RECURRENT NEURAL NETWORKS\"\n",
    "    http://www.cs.toronto.edu/~fritz/absps/RNN13.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, hidden_dim,\n",
    "                 hidden_activation=TT.tanh,\n",
    "                 rec_weight_init=None,\n",
    "                 weight_init=None, bias_init=None, \n",
    "                 forget_bias_init=None, \n",
    "                 **kwargs):\n",
    "        super(LSTM_RNN, self).__init__(**kwargs)\n",
    "        rec_weight_init = default(\n",
    "            rec_weight_init, IsotropicGaussian(1.0/sqrt(hidden_dim)))\n",
    "        weight_init = default(\n",
    "            weight_init, IsotropicGaussian(1.0/sqrt(in_dim)))\n",
    "        bias_init = default(\n",
    "            weight_init, Constant(0.))\n",
    "        forget_bias_init = default(\n",
    "            weight_init, Constant(1.))\n",
    "        self.hidden_activation = hidden_activation\n",
    "        \n",
    "        #\n",
    "        # Gates\n",
    "        #\n",
    "        \n",
    "        for gate in 'ifo':\n",
    "            self.add_param('Wx' + gate, (in_dim, hidden_dim), \n",
    "                           weight_init)\n",
    "            self.add_param('Wh' + gate, (hidden_dim, hidden_dim), \n",
    "                           weight_init)\n",
    "            # Note: a cell is only connected to its own gates\n",
    "            # Wc... are diagonal - so we allocate only a vector\n",
    "            # for them\n",
    "            self.add_param('Wc' + gate, (hidden_dim,), \n",
    "                           weight_init)\n",
    "            self.add_param('B' + gate, (hidden_dim,), \n",
    "                           bias_init)\n",
    "        \n",
    "        #\n",
    "        # Note - forget gate bias has a different initializer, because\n",
    "        # we often want to initialize it to 1\n",
    "        #\n",
    "        self.Bf.tag.initializer = forget_bias_init\n",
    "        \n",
    "        # Cell\n",
    "        self.add_param('Wxc', (in_dim, hidden_dim), \n",
    "                       weight_init)\n",
    "        self.add_param('Whc', (hidden_dim, hidden_dim), \n",
    "                       weight_init)\n",
    "        self.add_param('Bc', (hidden_dim,), \n",
    "                       bias_init)\n",
    "        \n",
    "        # Initial states\n",
    "        self.add_param('h0', (1, hidden_dim), \n",
    "                       bias_init)\n",
    "        self.initial_states.append(self.h0)\n",
    "        self.add_param('c0', (1, hidden_dim), \n",
    "                       bias_init)\n",
    "        self.initial_states.append(self.c0)\n",
    "        \n",
    "        \n",
    "    def transition(self, x, h, c):\n",
    "        \"\"\"\n",
    "        One step of LSTM transition.\n",
    "        \n",
    "        x is the previous input\n",
    "        h is the previous hidden state\n",
    "        c is the previous memory cell content\n",
    "        \"\"\"\n",
    "        \n",
    "        #\n",
    "        # Please note:\n",
    "        # The implementation below is not speed-optimal\n",
    "        # usually, it pays off to group similar matrix multiplications\n",
    "        # by grouping gates.\n",
    "        #\n",
    "        # Also, input-related computations should be moved out of scan since\n",
    "        # they can be done for all steps in parallel.\n",
    "        #\n",
    "        \n",
    "        \n",
    "        s = TT.nnet.sigmoid\n",
    "\n",
    "        # Note: for cells we do element0wise multiplication which \n",
    "        # is equvalent to a matrix multiplication with a diagonal matrix!\n",
    "        i = s(x.dot(self.Wxi) + h.dot(self.Whi) + c*self.Wci + self.Bi)\n",
    "        f = s(x.dot(self.Wxf) + h.dot(self.Whf) + c*self.Wcf + self.Bf)\n",
    "        \n",
    "        c_new = f*c + i*self.hidden_activation(x.dot(self.Wxc) + h.dot(self.Whc) + self.Bc)\n",
    "        o = s(x.dot(self.Wxo) + h.dot(self.Who) + c_new*self.Wco + self.Bo)\n",
    "        h_new = o * self.hidden_activation(c_new)\n",
    "        \n",
    "        return h_new, c_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we encode be input and output as a 1-of-N vector, thus every element of the input and output is a 1x10 vector with one '1'.\n",
    "\n",
    "def class_encoding(n, num_classes = 10):\n",
    "    ret = zeros(shape=(num_classes))\n",
    "    ret[n] = 1\n",
    "    return ret\n",
    "\n",
    "def class_decoding(v):\n",
    "    return argmax(v)\n",
    "\n",
    "# This should be rewritten without the use of loops\n",
    "\n",
    "def decode_matrix(matrix):\n",
    "    decoded_matrix = zeros(shape = (matrix.shape[0], matrix.shape[1]))\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            decoded_matrix[i][j] = class_decoding(matrix[i][j])\n",
    "    return decoded_matrix\n",
    "\n",
    "def encode_matrix(matrix, num_classes = 10):\n",
    "    encoded_matrix = zeros(shape = (matrix.shape[0], matrix.shape[1], num_classes))\n",
    "    for i in range(matrix.shape[0]):\n",
    "        for j in range(matrix.shape[1]):\n",
    "            encoded_matrix[i][j] = class_encoding(matrix[i][j])\n",
    "    return encoded_matrix.astype(\"float32\")\n",
    "\n",
    "\n",
    "def gen_copy_example(T, seq_len, batchsize):\n",
    "    rng = numpy.random\n",
    "    \n",
    "    sequence = rng.randint(2, 10, size=(seq_len, batchsize))\n",
    "    \n",
    "    X = np.concatenate((sequence,\n",
    "                         np.zeros(shape=(T - 1, batchsize)),\n",
    "                         np.ones(shape=(1, batchsize)), \n",
    "                         np.zeros(shape=(seq_len, batchsize))))\n",
    "    \n",
    "    Y = np.concatenate((np.zeros(shape=(T + seq_len, batchsize)),\n",
    "                        sequence.reshape(seq_len, batchsize)))\n",
    "    \n",
    "    \n",
    "    return encode_matrix(X), encode_matrix(Y)\n",
    "\n",
    "\n",
    "Xc, Yc = gen_copy_example(4, 4, 2)\n",
    "#print Xc.shape, Yc.shape\n",
    "#print 'X:', Xc[:,0,:], '\\nY:', Yc[:,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each point in time, network receives an input of size 1x10 (1-hot encoding), propagets the signal through a layer of\n",
    "hidden_dim LSTM neurons and produces an output of size 1x10 (also treated as 1-hot encoding). Softmax is applied at\n",
    "the end to get calculated probabilities. Cross-entropy is used as a loss function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CopyNet(Chain):\n",
    "    def __init__(self, hidden_dim, num_layers=1,\n",
    "                 **kwargs):\n",
    "        super(CopyNet, self).__init__(**kwargs)\n",
    "        self.recs = []\n",
    "        \n",
    "        for hid in xrange(num_layers):\n",
    "            if hid == 0:\n",
    "                in_dim = 10\n",
    "            else:\n",
    "                in_dim = hidden_dim\n",
    "                \n",
    "            rec = LSTM_RNN(in_dim=in_dim, hidden_dim=hidden_dim)\n",
    "            \n",
    "            self.recs.append(rec)\n",
    "            self.children.append(rec)\n",
    "        \n",
    "        self.merge = MergeInputHiddens(\n",
    "            in_dim=10, hidden_dim=hidden_dim,\n",
    "            out_dim=10\n",
    "            )\n",
    "        self.children.append(self.merge)\n",
    "        \n",
    "        self.X = TT.tensor3('X')\n",
    "        self.Y = TT.tensor3('Y')\n",
    "        \n",
    "        self.inputs = [self.X, self.Y]\n",
    "    \n",
    "    def apply(self, X):\n",
    "        H = X\n",
    "        for rec in self.recs:\n",
    "            H = rec.apply(H)\n",
    "            H = H[0] # we don't use cell contents\n",
    "        O = self.merge.apply(X, H)\n",
    "        \n",
    "        return softmax(O)\n",
    "    \n",
    "    # We use cross-entropy to measure the efficiency of the network. You can also a\n",
    "    def get_loss(self):\n",
    "        copy_net_output = self.apply(self.X)\n",
    "        # return ((copy_net_output - self.Y)**2).mean() # MSE\n",
    "        return -(self.Y * TT.log(copy_net_output)).mean() # cross entropy\n",
    "    \n",
    "    def get_output(self):\n",
    "        copy_net_output = self.apply(self.X)\n",
    "        return copy_net_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 1, 10) (24, 1, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pio/os/anaconda/lib/python2.7/site-packages/theano/scan_module/scan_perform_ext.py:133: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(0.2500729262828827, dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc, Yc = gen_copy_example(4, 10, 1)\n",
    "print Xc.shape, Yc.shape\n",
    "theano.config.compute_test_value='off'\n",
    "theano.config.print_test_value=True\n",
    "debug = False\n",
    "\n",
    "# Set the nubmer of hidden cells here. Note that intuitively you need more cells if you want to copy longer sequences. \n",
    "# The ratio 4 neurons per max seqence lenght seems to be fine.\n",
    "copy_net = CopyNet(hidden_dim=20)\n",
    "copy_net.initialize()\n",
    "copy_net_loss = copy_net.get_loss()\n",
    "copy_net_output = copy_net.get_output()\n",
    "\n",
    "copy_test_function = theano.function(copy_net.inputs, \n",
    "                                       copy_net_loss)\n",
    "copy_check_output = theano.function([copy_net.X], \n",
    "                                       copy_net_output)\n",
    "\n",
    "copy_test_function(Xc, Yc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "copy_trainer = Trainer(copy_net_loss, copy_net.parameters, copy_net.inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem we are solving is described in the following paper, section 5.1: http://arxiv.org/pdf/1511.06464v2.pdf.\n",
    "The input is a seqeunce of size 2 * n + T and each element of the input is of one of the 10 classes, which will name by the numbers from 0 to 9. First n elements is an arbitrary sequence of numbers 2...9. Then, T - 1 '0's follow. The next element is a single '1' and the last n elements are '0's. The desired output is a sequence of the same length, where the first T + n elemtnts are '0's followed by sequence from the beginnig of the input. The kth element of the output should be produced after the net sees the kth element of the input.\n",
    "\n",
    "The difficulty of the task is the fact that a network has to put elements in the memory, store them for a long time and then reproduce them. \n",
    "\n",
    "In the cited paper authors used n = 10 (length of the sequence to reproduce) and 40 neurons. Their network was only a little bit better than baseline (a program that outputs T + n '0's and n random numbers) when T = 100 and did not learn at all for larger T.\n",
    "\n",
    "It tunrs out that this task is in fact easy with the use of curriculum. My network was able to learn to perfectly reproduce the sequence with the time lag of 400.\n",
    "\n",
    "The curriculum is used both for the n (seq_len) as well as T (lag). In every consecutive batch the lag is of random size. As the newtork get better, we increase both the maximium allowed lag, as well as the sequnece lenght. After the training, the net should be able to copy a sequence of any length over any time lag not greater than the learnt ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [array(0.21623775362968445, dtype=float32), array(0.21651320159435272, dtype=float32), array(0.011847211979329586, dtype=float32)]\n",
      "0.206312388182\n",
      "[[ 9.]\n",
      " [ 1.]]\n",
      "2000 [array(0.004842719063162804, dtype=float32), array(0.005226113833487034, dtype=float32), array(0.00039847177686169744, dtype=float32)]\n",
      "0.00492117274553\n",
      "[[ 8.]\n",
      " [ 8.]]\n",
      "2152 Increasing lag to:  5 seq_len is  1\n",
      "2176 Increasing lag to:  6 seq_len is  1\n",
      "2304 Increasing lag to:  7 seq_len is  1\n",
      "2465 Increasing lag to:  8 seq_len is  1\n",
      "2487 Increasing lag to:  9 seq_len is  1\n",
      "2524 Increasing lag to:  10 seq_len is  2\n",
      "4000 [array(0.0011435147607699037, dtype=float32), array(0.0015809070318937302, dtype=float32), array(0.00024957634741440415, dtype=float32)]\n",
      "0.0186348594725\n",
      "[[ 8.  4.]\n",
      " [ 8.  8.]]\n",
      "6000 [array(0.012511874549090862, dtype=float32), array(0.012996983714401722, dtype=float32), array(0.0014367931289598346, dtype=float32)]\n",
      "0.0113470060751\n",
      "[[ 7.  4.]\n",
      " [ 7.  7.]]\n",
      "8000 [array(0.00022067397367209196, dtype=float32), array(0.0007458472391590476, dtype=float32), array(3.9607770304428414e-05, dtype=float32)]\n",
      "0.0072632827796\n",
      "[[ 9.  6.]\n",
      " [ 9.  6.]]\n",
      "10000 [array(0.00014251793618313968, dtype=float32), array(0.0007054418092593551, dtype=float32), array(5.6389458222838584e-06, dtype=float32)]\n",
      "0.00462869741023\n",
      "[[ 6.  7.]\n",
      " [ 6.  7.]]\n",
      "10553 Increasing lag to:  11 seq_len is  2\n",
      "10585 Increasing lag to:  12 seq_len is  2\n",
      "10697 Increasing lag to:  13 seq_len is  2\n",
      "10735 Increasing lag to:  14 seq_len is  2\n",
      "11011 Increasing lag to:  15 seq_len is  2\n",
      "11133 Increasing lag to:  16 seq_len is  2\n",
      "11303 Increasing lag to:  17 seq_len is  2\n",
      "11340 Increasing lag to:  18 seq_len is  2\n",
      "11342 Increasing lag to:  19 seq_len is  2\n",
      "11513 Increasing lag to:  20 seq_len is  3\n",
      "12000 [array(0.005050615407526493, dtype=float32), array(0.005640305578708649, dtype=float32), array(0.001773955998942256, dtype=float32)]\n",
      "0.0148089695722\n",
      "[[ 8.  6.  6.]\n",
      " [ 8.  5.  6.]]\n",
      "14000 [array(0.00020916461653541774, dtype=float32), array(0.0008207443752326071, dtype=float32), array(4.7318249016825575e-06, dtype=float32)]\n",
      "0.0123068606481\n",
      "[[ 2.  6.  5.]\n",
      " [ 2.  6.  3.]]\n",
      "16000 [array(0.010129493661224842, dtype=float32), array(0.01076800748705864, dtype=float32), array(0.1481095552444458, dtype=float32)]\n",
      "0.0102896820754\n",
      "[[ 4.  2.  7.]\n",
      " [ 4.  2.  2.]]\n",
      "18000 [array(0.002031321171671152, dtype=float32), array(0.002696174895390868, dtype=float32), array(7.709155761403963e-05, dtype=float32)]\n",
      "0.00577622000128\n",
      "[[ 6.  9.  6.]\n",
      " [ 6.  9.  6.]]\n",
      "20000 [array(0.0026138341054320335, dtype=float32), array(0.003301969263702631, dtype=float32), array(0.00013623338600154966, dtype=float32)]\n",
      "0.0062317722477\n",
      "[[ 7.  5.  4.]\n",
      " [ 7.  5.  7.]]\n",
      "22000 [array(0.006388348527252674, dtype=float32), array(0.0070975725539028645, dtype=float32), array(0.0018597036832943559, dtype=float32)]\n",
      "0.00549381412566\n",
      "[[ 9.  6.  6.]\n",
      " [ 9.  6.  6.]]\n",
      "24000 [array(0.00011013033508788794, dtype=float32), array(0.0008410708396695554, dtype=float32), array(3.6195189068166655e-07, dtype=float32)]\n",
      "0.00364733673632\n",
      "[[ 7.  3.  3.]\n",
      " [ 4.  3.  3.]]\n",
      "26000 [array(6.429160566767678e-05, dtype=float32), array(0.0008164879400283098, dtype=float32), array(2.895174247896648e-06, dtype=float32)]\n",
      "0.0038499168586\n",
      "[[ 5.  6.  2.]\n",
      " [ 5.  6.  2.]]\n",
      "26183 Increasing lag to:  21 seq_len is  3\n",
      "26205 Increasing lag to:  22 seq_len is  3\n",
      "26675 Increasing lag to:  23 seq_len is  3\n",
      "26841 Increasing lag to:  24 seq_len is  3\n",
      "26931 Increasing lag to:  25 seq_len is  3\n",
      "27196 Increasing lag to:  26 seq_len is  3\n",
      "27305 Increasing lag to:  27 seq_len is  3\n",
      "27578 Increasing lag to:  28 seq_len is  3\n",
      "27610 Increasing lag to:  29 seq_len is  3\n",
      "27632 Increasing lag to:  30 seq_len is  4\n",
      "28000 [array(0.0007694163941778243, dtype=float32), array(0.0015378831885755062, dtype=float32), array(0.0002836407511495054, dtype=float32)]\n",
      "0.0107415970415\n",
      "[[ 2.  4.  3.  4.]\n",
      " [ 4.  4.  3.  3.]]\n",
      "30000 [array(6.786878657294437e-05, dtype=float32), array(0.0008489906904287636, dtype=float32), array(2.4276462795569387e-07, dtype=float32)]\n",
      "0.00802908279002\n",
      "[[ 2.  2.  3.  5.]\n",
      " [ 2.  2.  5.  3.]]\n",
      "32000 [array(6.129742541816086e-05, dtype=float32), array(0.000859326682984829, dtype=float32), array(1.7424288500933471e-07, dtype=float32)]\n",
      "0.00969861168414\n",
      "[[ 4.  4.  3.  4.]\n",
      " [ 4.  4.  4.  4.]]\n",
      "34000 [array(0.0017717123264446855, dtype=float32), array(0.0025893361307680607, dtype=float32), array(0.00012789876200258732, dtype=float32)]\n",
      "0.00824418198317\n",
      "[[ 9.  8.  3.  5.]\n",
      " [ 8.  9.  3.  5.]]\n",
      "36000 [array(0.0003375664527993649, dtype=float32), array(0.001175213372334838, dtype=float32), array(1.6375573750337935e-06, dtype=float32)]\n",
      "0.00735715543851\n",
      "[[ 9.  5.  9.  7.]\n",
      " [ 9.  5.  9.  7.]]\n",
      "38000 [array(0.0003784329746849835, dtype=float32), array(0.001235293224453926, dtype=float32), array(1.0215697329840623e-05, dtype=float32)]\n",
      "0.00656051700935\n",
      "[[ 5.  8.  5.  3.]\n",
      " [ 5.  8.  5.  3.]]\n",
      "40000 [array(0.00042887707240879536, dtype=float32), array(0.0013039237819612026, dtype=float32), array(0.00010323301830794662, dtype=float32)]\n",
      "0.00562733691186\n",
      "[[ 4.  7.  5.  9.]\n",
      " [ 4.  7.  5.  7.]]\n",
      "42000 [array(0.005545004736632109, dtype=float32), array(0.006438614334911108, dtype=float32), array(0.001286394544877112, dtype=float32)]\n",
      "0.00399979902431\n",
      "[[ 9.  9.  9.  6.]\n",
      " [ 9.  9.  9.  6.]]\n",
      "44000 [array(0.0013203283306211233, dtype=float32), array(0.0022286828607320786, dtype=float32), array(3.2875457691261545e-05, dtype=float32)]\n",
      "0.00384833547287\n",
      "[[ 4.  7.  7.  9.]\n",
      " [ 4.  7.  7.  9.]]\n",
      "44819 Increasing lag to:  31 seq_len is  4\n",
      "45044 Increasing lag to:  32 seq_len is  4\n",
      "45481 Increasing lag to:  33 seq_len is  4\n",
      "45550 Increasing lag to:  34 seq_len is  4\n",
      "45794 Increasing lag to:  35 seq_len is  4\n",
      "46000 [array(0.0043007927015423775, dtype=float32), array(0.005224565975368023, dtype=float32), array(0.0012394197983667254, dtype=float32)]\n",
      "0.00346407108009\n",
      "[[ 8.  8.  9.  2.]\n",
      " [ 8.  8.  2.  9.]]\n",
      "46233 Increasing lag to:  36 seq_len is  4\n",
      "46249 Increasing lag to:  37 seq_len is  4\n",
      "46391 Increasing lag to:  38 seq_len is  4\n",
      "46545 Increasing lag to:  39 seq_len is  4\n",
      "46561 Increasing lag to:  40 seq_len is  5\n",
      "48000 [array(0.00479601975530386, dtype=float32), array(0.005726397968828678, dtype=float32), array(0.003361143171787262, dtype=float32)]\n",
      "0.00948259513825\n",
      "[[ 8.  9.  9.  8.  9.]\n",
      " [ 8.  8.  9.  9.  6.]]\n",
      "50000 [array(0.001436917344108224, dtype=float32), array(0.002378585748374462, dtype=float32), array(9.191483695758507e-05, dtype=float32)]\n",
      "0.00701159005985\n",
      "[[ 7.  3.  8.  2.  9.]\n",
      " [ 7.  3.  8.  2.  5.]]\n",
      "52000 [array(0.008095407858490944, dtype=float32), array(0.009051479399204254, dtype=float32), array(0.0008804297540336847, dtype=float32)]\n",
      "0.00628958735615\n",
      "[[ 2.  2.  3.  8.  3.]\n",
      " [ 2.  2.  3.  8.  3.]]\n",
      "54000 [array(0.0021062525920569897, dtype=float32), array(0.0030763642862439156, dtype=float32), array(3.1691753974882886e-05, dtype=float32)]\n",
      "0.00586198549718\n",
      "[[ 5.  5.  9.  5.  8.]\n",
      " [ 5.  5.  8.  5.  5.]]\n",
      "56000 [array(0.005570165812969208, dtype=float32), array(0.006553749553859234, dtype=float32), array(0.0008516422240063548, dtype=float32)]\n",
      "0.00628679525107\n",
      "[[ 4.  8.  9.  8.  3.]\n",
      " [ 4.  8.  9.  9.  6.]]\n",
      "58000 [array(0.006782609038054943, dtype=float32), array(0.00777902826666832, dtype=float32), array(0.0015201692003756762, dtype=float32)]\n",
      "0.00641289213672\n",
      "[[ 4.  2.  7.  3.  3.]\n",
      " [ 4.  7.  7.  3.  7.]]\n",
      "60000 [array(0.000193295200006105, dtype=float32), array(0.0012023253366351128, dtype=float32), array(1.0519277111598058e-06, dtype=float32)]\n",
      "0.0055784243159\n",
      "[[ 5.  9.  9.  5.  7.]\n",
      " [ 5.  9.  9.  5.  7.]]\n",
      "62000 [array(3.750345786102116e-05, dtype=float32), array(0.0010586273856461048, dtype=float32), array(4.2677125833279206e-08, dtype=float32)]\n",
      "0.0046484451741\n",
      "[[ 9.  4.  2.  6.  9.]\n",
      " [ 9.  4.  2.  6.  9.]]\n",
      "64000 [array(3.392681173863821e-05, dtype=float32), array(0.0010667528258636594, dtype=float32), array(3.31994023383686e-08, dtype=float32)]\n",
      "0.00641810055822\n",
      "[[ 9.  3.  7.  8.  8.]\n",
      " [ 9.  3.  7.  8.  6.]]\n",
      "66000 [array(1.7128948456957005e-05, dtype=float32), array(0.0010617414955049753, dtype=float32), array(8.095440762190265e-09, dtype=float32)]\n",
      "0.0120776584372\n",
      "[[ 4.  5.  5.  6.  6.]\n",
      " [ 3.  8.  5.  6.  6.]]\n",
      "68000 [array(2.745214987953659e-05, dtype=float32), array(0.0010835430584847927, dtype=float32), array(2.5470752618161896e-08, dtype=float32)]\n",
      "0.00561593007296\n",
      "[[ 6.  4.  2.  7.  9.]\n",
      " [ 6.  4.  2.  2.  9.]]\n",
      "70000 [array(0.011144019663333893, dtype=float32), array(0.012210922315716743, dtype=float32), array(0.05839752405881882, dtype=float32)]\n",
      "0.00990253407508\n",
      "[[ 7.  2.  3.  5.  9.]\n",
      " [ 7.  2.  2.  5.  3.]]\n",
      "72000 [array(0.0004651323542930186, dtype=float32), array(0.0015407130122184753, dtype=float32), array(2.8478505100792972e-06, dtype=float32)]\n",
      "0.00360240903683\n",
      "[[ 2.  3.  5.  9.  4.]\n",
      " [ 2.  3.  5.  9.  4.]]\n",
      "74000 [array(0.006875389255583286, dtype=float32), array(0.007958736270666122, dtype=float32), array(0.0008116864482872188, dtype=float32)]\n",
      "0.0038431447465\n",
      "[[ 8.  8.  5.  2.  4.]\n",
      " [ 8.  8.  5.  2.  4.]]\n",
      "74005 Increasing lag to:  41 seq_len is  5\n",
      "75861 Increasing lag to:  42 seq_len is  5\n",
      "76000 [array(0.0045048389583826065, dtype=float32), array(0.0055961646139621735, dtype=float32), array(0.004097818862646818, dtype=float32)]\n",
      "0.00569743663073\n",
      "[[ 3.  7.  7.  3.  6.]\n",
      " [ 4.  6.  7.  7.  6.]]\n",
      "76484 Increasing lag to:  43 seq_len is  5\n",
      "76881 Increasing lag to:  44 seq_len is  5\n",
      "77229 Increasing lag to:  45 seq_len is  5\n",
      "77289 Increasing lag to:  46 seq_len is  5\n",
      "77299 Increasing lag to:  47 seq_len is  5\n",
      "77540 Increasing lag to:  48 seq_len is  5\n",
      "77746 Increasing lag to:  49 seq_len is  5\n",
      "78000 [array(0.00022162690584082156, dtype=float32), array(0.0013199957320466638, dtype=float32), array(8.789575076662004e-07, dtype=float32)]\n",
      "0.00301889167167\n",
      "[[ 9.  7.  2.  5.  4.]\n",
      " [ 9.  7.  2.  5.  4.]]\n",
      "78221 Increasing lag to:  50 seq_len is  5\n",
      "78231 Increasing lag to:  51 seq_len is  5\n",
      "78347 Increasing lag to:  52 seq_len is  5\n",
      "78392 Increasing lag to:  53 seq_len is  5\n",
      "78450 Increasing lag to:  54 seq_len is  5\n",
      "78570 Increasing lag to:  55 seq_len is  5\n",
      "78593 Increasing lag to:  56 seq_len is  5\n",
      "78659 Increasing lag to:  57 seq_len is  5\n",
      "78816 Increasing lag to:  58 seq_len is  5\n",
      "78908 Increasing lag to:  59 seq_len is  5\n",
      "78987 Increasing lag to:  60 seq_len is  5\n",
      "79268 Increasing lag to:  61 seq_len is  5\n",
      "79278 Increasing lag to:  62 seq_len is  5\n",
      "79282 Increasing lag to:  63 seq_len is  5\n",
      "79292 Increasing lag to:  64 seq_len is  5\n",
      "79430 Increasing lag to:  65 seq_len is  5\n",
      "79479 Increasing lag to:  66 seq_len is  5\n",
      "79523 Increasing lag to:  67 seq_len is  5\n",
      "79603 Increasing lag to:  68 seq_len is  5\n",
      "79759 Increasing lag to:  69 seq_len is  5\n",
      "79841 Increasing lag to:  70 seq_len is  5\n",
      "79860 Increasing lag to:  71 seq_len is  5\n",
      "79880 Increasing lag to:  72 seq_len is  5\n",
      "79886 Increasing lag to:  73 seq_len is  5\n",
      "79997 Increasing lag to:  74 seq_len is  5\n",
      "80000 [array(0.0018202827777713537, dtype=float32), array(0.0029237798880785704, dtype=float32), array(0.0005420665256679058, dtype=float32)]\n",
      "0.00288499915041\n",
      "[[ 8.  8.  7.  6.  8.]\n",
      " [ 8.  8.  7.  6.  8.]]\n",
      "80040 Increasing lag to:  75 seq_len is  5\n",
      "80186 Increasing lag to:  76 seq_len is  5\n",
      "80279 Increasing lag to:  77 seq_len is  5\n",
      "80285 Increasing lag to:  78 seq_len is  5\n",
      "80311 Increasing lag to:  79 seq_len is  5\n",
      "80369 Increasing lag to:  80 seq_len is  5\n",
      "80382 Increasing lag to:  81 seq_len is  5\n",
      "80383 Increasing lag to:  82 seq_len is  5\n",
      "80455 Increasing lag to:  83 seq_len is  5\n",
      "80463 Increasing lag to:  84 seq_len is  5\n",
      "80513 Increasing lag to:  85 seq_len is  5\n",
      "80540 Increasing lag to:  86 seq_len is  5\n",
      "80581 Increasing lag to:  87 seq_len is  5\n",
      "80636 Increasing lag to:  88 seq_len is  5\n",
      "80661 Increasing lag to:  89 seq_len is  5\n",
      "80792 Increasing lag to:  90 seq_len is  5\n",
      "80802 Increasing lag to:  91 seq_len is  5\n",
      "80804 Increasing lag to:  92 seq_len is  5\n",
      "80825 Increasing lag to:  93 seq_len is  5\n",
      "80835 Increasing lag to:  94 seq_len is  5\n",
      "80898 Increasing lag to:  95 seq_len is  5\n",
      "80953 Increasing lag to:  96 seq_len is  5\n",
      "80959 Increasing lag to:  97 seq_len is  5\n",
      "81022 Increasing lag to:  98 seq_len is  5\n",
      "81047 Increasing lag to:  99 seq_len is  5\n",
      "81111 Increasing lag to:  100 seq_len is  5\n",
      "81119 Increasing lag to:  101 seq_len is  5\n",
      "81140 Increasing lag to:  102 seq_len is  5\n",
      "81239 Increasing lag to:  103 seq_len is  5\n",
      "81398 Increasing lag to:  104 seq_len is  5\n",
      "81490 Increasing lag to:  105 seq_len is  5\n",
      "81495 Increasing lag to:  106 seq_len is  5\n",
      "81518 Increasing lag to:  107 seq_len is  5\n",
      "81553 Increasing lag to:  108 seq_len is  5\n",
      "81616 Increasing lag to:  109 seq_len is  5\n",
      "81653 Increasing lag to:  110 seq_len is  5\n",
      "81654 Increasing lag to:  111 seq_len is  5\n",
      "81685 Increasing lag to:  112 seq_len is  5\n",
      "81703 Increasing lag to:  113 seq_len is  5\n",
      "81758 Increasing lag to:  114 seq_len is  5\n",
      "81799 Increasing lag to:  115 seq_len is  5\n",
      "81859 Increasing lag to:  116 seq_len is  5\n",
      "81886 Increasing lag to:  117 seq_len is  5\n",
      "81943 Increasing lag to:  118 seq_len is  5\n",
      "82000 [array(7.683291914872825e-05, dtype=float32), array(0.001184097840450704, dtype=float32), array(8.773849003773648e-06, dtype=float32)]\n",
      "0.00246633030474\n",
      "[[ 6.  5.  9.  7.  5.]\n",
      " [ 6.  5.  9.  7.  7.]]\n",
      "82023 Increasing lag to:  119 seq_len is  5\n",
      "82103 Increasing lag to:  120 seq_len is  5\n",
      "82200 Increasing lag to:  121 seq_len is  5\n",
      "82215 Increasing lag to:  122 seq_len is  5\n",
      "82225 Increasing lag to:  123 seq_len is  5\n",
      "82251 Increasing lag to:  124 seq_len is  5\n",
      "82298 Increasing lag to:  125 seq_len is  5\n",
      "82406 Increasing lag to:  126 seq_len is  5\n",
      "82485 Increasing lag to:  127 seq_len is  5\n",
      "82548 Increasing lag to:  128 seq_len is  5\n",
      "82639 Increasing lag to:  129 seq_len is  5\n",
      "82699 Increasing lag to:  130 seq_len is  5\n",
      "82747 Increasing lag to:  131 seq_len is  5\n",
      "82771 Increasing lag to:  132 seq_len is  5\n",
      "82782 Increasing lag to:  133 seq_len is  5\n",
      "82822 Increasing lag to:  134 seq_len is  5\n",
      "82828 Increasing lag to:  135 seq_len is  5\n",
      "82856 Increasing lag to:  136 seq_len is  5\n",
      "82868 Increasing lag to:  137 seq_len is  5\n",
      "82879 Increasing lag to:  138 seq_len is  5\n",
      "82910 Increasing lag to:  139 seq_len is  5\n",
      "82933 Increasing lag to:  140 seq_len is  5\n",
      "82982 Increasing lag to:  141 seq_len is  5\n",
      "82998 Increasing lag to:  142 seq_len is  5\n",
      "83068 Increasing lag to:  143 seq_len is  5\n",
      "83073 Increasing lag to:  144 seq_len is  5\n",
      "83181 Increasing lag to:  145 seq_len is  5\n",
      "83232 Increasing lag to:  146 seq_len is  5\n",
      "83268 Increasing lag to:  147 seq_len is  5\n",
      "83285 Increasing lag to:  148 seq_len is  5\n",
      "83358 Increasing lag to:  149 seq_len is  5\n",
      "83534 Increasing lag to:  150 seq_len is  5\n",
      "83547 Increasing lag to:  151 seq_len is  5\n",
      "83698 Increasing lag to:  152 seq_len is  5\n",
      "83729 Increasing lag to:  153 seq_len is  5\n",
      "83774 Increasing lag to:  154 seq_len is  5\n",
      "83825 Increasing lag to:  155 seq_len is  5\n",
      "83855 Increasing lag to:  156 seq_len is  5\n",
      "83910 Increasing lag to:  157 seq_len is  5\n",
      "84000 [array(1.1873804396600462e-05, dtype=float32), array(0.0011207186616957188, dtype=float32), array(9.873763140433311e-09, dtype=float32)]\n",
      "0.00192991399672\n",
      "[[ 4.  4.  2.  5.  2.]\n",
      " [ 4.  2.  2.  5.  2.]]\n",
      "84079 Increasing lag to:  158 seq_len is  5\n",
      "84308 Increasing lag to:  159 seq_len is  5\n",
      "84349 Increasing lag to:  160 seq_len is  5\n",
      "84389 Increasing lag to:  161 seq_len is  5\n",
      "84488 Increasing lag to:  162 seq_len is  5\n",
      "84499 Increasing lag to:  163 seq_len is  5\n",
      "84588 Increasing lag to:  164 seq_len is  5\n",
      "84667 Increasing lag to:  165 seq_len is  5\n",
      "84672 Increasing lag to:  166 seq_len is  5\n",
      "84721 Increasing lag to:  167 seq_len is  5\n",
      "84750 Increasing lag to:  168 seq_len is  5\n",
      "84799 Increasing lag to:  169 seq_len is  5\n",
      "84872 Increasing lag to:  170 seq_len is  5\n",
      "84890 Increasing lag to:  171 seq_len is  5\n",
      "84932 Increasing lag to:  172 seq_len is  5\n",
      "85056 Increasing lag to:  173 seq_len is  5\n",
      "85072 Increasing lag to:  174 seq_len is  5\n",
      "85098 Increasing lag to:  175 seq_len is  5\n",
      "85102 Increasing lag to:  176 seq_len is  5\n",
      "85170 Increasing lag to:  177 seq_len is  5\n",
      "85184 Increasing lag to:  178 seq_len is  5\n",
      "85201 Increasing lag to:  179 seq_len is  5\n",
      "85429 Increasing lag to:  180 seq_len is  5\n",
      "85442 Increasing lag to:  181 seq_len is  5\n",
      "85466 Increasing lag to:  182 seq_len is  5\n",
      "85523 Increasing lag to:  183 seq_len is  5\n",
      "85736 Increasing lag to:  184 seq_len is  5\n",
      "85741 Increasing lag to:  185 seq_len is  5\n",
      "85782 Increasing lag to:  186 seq_len is  5\n",
      "85824 Increasing lag to:  187 seq_len is  5\n",
      "85835 Increasing lag to:  188 seq_len is  5\n",
      "85880 Increasing lag to:  189 seq_len is  5\n",
      "85909 Increasing lag to:  190 seq_len is  5\n",
      "85988 Increasing lag to:  191 seq_len is  5\n",
      "86000 [array(0.0004751837404910475, dtype=float32), array(0.0015824389411136508, dtype=float32), array(0.00010173192276852205, dtype=float32)]\n",
      "0.00112055824138\n",
      "[[ 9.  8.  8.  4.  6.]\n",
      " [ 9.  8.  8.  4.  5.]]\n",
      "86048 Increasing lag to:  192 seq_len is  5\n",
      "86149 Increasing lag to:  193 seq_len is  5\n",
      "86165 Increasing lag to:  194 seq_len is  5\n",
      "86208 Increasing lag to:  195 seq_len is  5\n",
      "86264 Increasing lag to:  196 seq_len is  5\n",
      "86267 Increasing lag to:  197 seq_len is  5\n",
      "86280 Increasing lag to:  198 seq_len is  5\n",
      "86380 Increasing lag to:  199 seq_len is  5\n",
      "86408 Increasing lag to:  200 seq_len is  5\n",
      "86417 Increasing lag to:  201 seq_len is  5\n",
      "86466 Increasing lag to:  202 seq_len is  5\n",
      "86572 Increasing lag to:  203 seq_len is  5\n",
      "86653 Increasing lag to:  204 seq_len is  5\n",
      "86700 Increasing lag to:  205 seq_len is  5\n",
      "86715 Increasing lag to:  206 seq_len is  5\n",
      "86786 Increasing lag to:  207 seq_len is  5\n",
      "86790 Increasing lag to:  208 seq_len is  5\n",
      "87011 Increasing lag to:  209 seq_len is  5\n",
      "87057 Increasing lag to:  210 seq_len is  5\n",
      "87126 Increasing lag to:  211 seq_len is  5\n",
      "87284 Increasing lag to:  212 seq_len is  5\n",
      "87304 Increasing lag to:  213 seq_len is  5\n",
      "87321 Increasing lag to:  214 seq_len is  5\n",
      "87372 Increasing lag to:  215 seq_len is  5\n",
      "87387 Increasing lag to:  216 seq_len is  5\n",
      "87437 Increasing lag to:  217 seq_len is  5\n",
      "87480 Increasing lag to:  218 seq_len is  5\n",
      "87495 Increasing lag to:  219 seq_len is  5\n",
      "87500 Increasing lag to:  220 seq_len is  5\n",
      "87579 Increasing lag to:  221 seq_len is  5\n",
      "87581 Increasing lag to:  222 seq_len is  5\n",
      "87595 Increasing lag to:  223 seq_len is  5\n",
      "87610 Increasing lag to:  224 seq_len is  5\n",
      "87625 Increasing lag to:  225 seq_len is  5\n",
      "87646 Increasing lag to:  226 seq_len is  5\n",
      "87675 Increasing lag to:  227 seq_len is  5\n",
      "87762 Increasing lag to:  228 seq_len is  5\n",
      "87797 Increasing lag to:  229 seq_len is  5\n",
      "87816 Increasing lag to:  230 seq_len is  5\n",
      "87845 Increasing lag to:  231 seq_len is  5\n",
      "87858 Increasing lag to:  232 seq_len is  5\n",
      "87872 Increasing lag to:  233 seq_len is  5\n",
      "87874 Increasing lag to:  234 seq_len is  5\n",
      "87901 Increasing lag to:  235 seq_len is  5\n",
      "88000 [array(5.835489719174802e-05, dtype=float32), array(0.0011628299253061414, dtype=float32), array(2.1472474998063262e-07, dtype=float32)]\n",
      "0.00134200486355\n",
      "[[ 9.  9.  4.  9.  8.]\n",
      " [ 9.  9.  4.  9.  9.]]\n",
      "88030 Increasing lag to:  236 seq_len is  5\n",
      "88043 Increasing lag to:  237 seq_len is  5\n",
      "88082 Increasing lag to:  238 seq_len is  5\n",
      "88121 Increasing lag to:  239 seq_len is  5\n",
      "88230 Increasing lag to:  240 seq_len is  5\n",
      "88237 Increasing lag to:  241 seq_len is  5\n",
      "88262 Increasing lag to:  242 seq_len is  5\n",
      "88406 Increasing lag to:  243 seq_len is  5\n",
      "88452 Increasing lag to:  244 seq_len is  5\n",
      "88465 Increasing lag to:  245 seq_len is  5\n",
      "88487 Increasing lag to:  246 seq_len is  5\n",
      "88755 Increasing lag to:  247 seq_len is  5\n",
      "88830 Increasing lag to:  248 seq_len is  5\n",
      "88905 Increasing lag to:  249 seq_len is  5\n",
      "88930 Increasing lag to:  250 seq_len is  5\n",
      "88939 Increasing lag to:  251 seq_len is  5\n",
      "88992 Increasing lag to:  252 seq_len is  5\n",
      "89001 Increasing lag to:  253 seq_len is  5\n",
      "89021 Increasing lag to:  254 seq_len is  5\n",
      "89083 Increasing lag to:  255 seq_len is  5\n",
      "89090 Increasing lag to:  256 seq_len is  5\n",
      "89116 Increasing lag to:  257 seq_len is  5\n",
      "89121 Increasing lag to:  258 seq_len is  5\n",
      "89139 Increasing lag to:  259 seq_len is  5\n",
      "89175 Increasing lag to:  260 seq_len is  5\n",
      "89194 Increasing lag to:  261 seq_len is  5\n",
      "89219 Increasing lag to:  262 seq_len is  5\n",
      "89226 Increasing lag to:  263 seq_len is  5\n",
      "89373 Increasing lag to:  264 seq_len is  5\n",
      "89393 Increasing lag to:  265 seq_len is  5\n",
      "89425 Increasing lag to:  266 seq_len is  5\n",
      "89447 Increasing lag to:  267 seq_len is  5\n",
      "89456 Increasing lag to:  268 seq_len is  5\n",
      "89515 Increasing lag to:  269 seq_len is  5\n",
      "89526 Increasing lag to:  270 seq_len is  5\n",
      "89593 Increasing lag to:  271 seq_len is  5\n",
      "89625 Increasing lag to:  272 seq_len is  5\n",
      "89740 Increasing lag to:  273 seq_len is  5\n",
      "89743 Increasing lag to:  274 seq_len is  5\n",
      "89785 Increasing lag to:  275 seq_len is  5\n",
      "89823 Increasing lag to:  276 seq_len is  5\n",
      "90000 [array(1.805292777135037e-05, dtype=float32), array(0.001118902349844575, dtype=float32), array(5.514380774229721e-08, dtype=float32)]\n",
      "0.00132937426679\n",
      "[[ 6.  9.  6.  7.  9.]\n",
      " [ 6.  9.  6.  7.  9.]]\n",
      "90024 Increasing lag to:  277 seq_len is  5\n",
      "90063 Increasing lag to:  278 seq_len is  5\n",
      "90173 Increasing lag to:  279 seq_len is  5\n",
      "90188 Increasing lag to:  280 seq_len is  5\n",
      "90209 Increasing lag to:  281 seq_len is  5\n",
      "90234 Increasing lag to:  282 seq_len is  5\n",
      "90278 Increasing lag to:  283 seq_len is  5\n",
      "90322 Increasing lag to:  284 seq_len is  5\n",
      "90384 Increasing lag to:  285 seq_len is  5\n",
      "90422 Increasing lag to:  286 seq_len is  5\n",
      "90439 Increasing lag to:  287 seq_len is  5\n",
      "90464 Increasing lag to:  288 seq_len is  5\n",
      "90551 Increasing lag to:  289 seq_len is  5\n",
      "90562 Increasing lag to:  290 seq_len is  5\n",
      "90573 Increasing lag to:  291 seq_len is  5\n",
      "90662 Increasing lag to:  292 seq_len is  5\n",
      "90717 Increasing lag to:  293 seq_len is  5\n",
      "90719 Increasing lag to:  294 seq_len is  5\n",
      "90785 Increasing lag to:  295 seq_len is  5\n",
      "90925 Increasing lag to:  296 seq_len is  5\n",
      "90957 Increasing lag to:  297 seq_len is  5\n",
      "91008 Increasing lag to:  298 seq_len is  5\n",
      "91013 Increasing lag to:  299 seq_len is  5\n",
      "91016 Increasing lag to:  300 seq_len is  5\n",
      "91031 Increasing lag to:  301 seq_len is  5\n",
      "91047 Increasing lag to:  302 seq_len is  5\n",
      "91104 Increasing lag to:  303 seq_len is  5\n",
      "91110 Increasing lag to:  304 seq_len is  5\n",
      "91115 Increasing lag to:  305 seq_len is  5\n",
      "91168 Increasing lag to:  306 seq_len is  5\n",
      "91172 Increasing lag to:  307 seq_len is  5\n",
      "91186 Increasing lag to:  308 seq_len is  5\n",
      "91243 Increasing lag to:  309 seq_len is  5\n",
      "91259 Increasing lag to:  310 seq_len is  5\n",
      "91271 Increasing lag to:  311 seq_len is  5\n",
      "91308 Increasing lag to:  312 seq_len is  5\n",
      "91360 Increasing lag to:  313 seq_len is  5\n",
      "91669 Increasing lag to:  314 seq_len is  5\n",
      "91780 Increasing lag to:  315 seq_len is  5\n",
      "91840 Increasing lag to:  316 seq_len is  5\n",
      "91877 Increasing lag to:  317 seq_len is  5\n",
      "91896 Increasing lag to:  318 seq_len is  5\n",
      "91918 Increasing lag to:  319 seq_len is  5\n",
      "91943 Increasing lag to:  320 seq_len is  5\n",
      "91953 Increasing lag to:  321 seq_len is  5\n",
      "92000 [array(5.344491910364013e-06, dtype=float32), array(0.0011029542656615376, dtype=float32), array(6.002263130966412e-09, dtype=float32)]\n",
      "0.000665155472234\n",
      "[[ 2.  4.  4.  3.  2.]\n",
      " [ 2.  4.  2.  3.  4.]]\n",
      "92030 Increasing lag to:  322 seq_len is  5\n",
      "92077 Increasing lag to:  323 seq_len is  5\n",
      "92113 Increasing lag to:  324 seq_len is  5\n",
      "92166 Increasing lag to:  325 seq_len is  5\n",
      "92180 Increasing lag to:  326 seq_len is  5\n",
      "92181 Increasing lag to:  327 seq_len is  5\n",
      "92199 Increasing lag to:  328 seq_len is  5\n",
      "92337 Increasing lag to:  329 seq_len is  5\n",
      "92422 Increasing lag to:  330 seq_len is  5\n",
      "92507 Increasing lag to:  331 seq_len is  5\n",
      "92586 Increasing lag to:  332 seq_len is  5\n",
      "92641 Increasing lag to:  333 seq_len is  5\n",
      "92696 Increasing lag to:  334 seq_len is  5\n",
      "92702 Increasing lag to:  335 seq_len is  5\n",
      "92728 Increasing lag to:  336 seq_len is  5\n",
      "92739 Increasing lag to:  337 seq_len is  5\n",
      "92775 Increasing lag to:  338 seq_len is  5\n",
      "92871 Increasing lag to:  339 seq_len is  5\n",
      "92914 Increasing lag to:  340 seq_len is  5\n",
      "92932 Increasing lag to:  341 seq_len is  5\n",
      "92997 Increasing lag to:  342 seq_len is  5\n",
      "93010 Increasing lag to:  343 seq_len is  5\n",
      "93015 Increasing lag to:  344 seq_len is  5\n",
      "93048 Increasing lag to:  345 seq_len is  5\n",
      "93069 Increasing lag to:  346 seq_len is  5\n",
      "93071 Increasing lag to:  347 seq_len is  5\n",
      "93158 Increasing lag to:  348 seq_len is  5\n",
      "93196 Increasing lag to:  349 seq_len is  5\n",
      "93201 Increasing lag to:  350 seq_len is  5\n",
      "93267 Increasing lag to:  351 seq_len is  5\n",
      "93393 Increasing lag to:  352 seq_len is  5\n",
      "93443 Increasing lag to:  353 seq_len is  5\n",
      "93482 Increasing lag to:  354 seq_len is  5\n",
      "93519 Increasing lag to:  355 seq_len is  5\n",
      "93530 Increasing lag to:  356 seq_len is  5\n",
      "93674 Increasing lag to:  357 seq_len is  5\n",
      "93732 Increasing lag to:  358 seq_len is  5\n",
      "93735 Increasing lag to:  359 seq_len is  5\n",
      "93800 Increasing lag to:  360 seq_len is  5\n",
      "93822 Increasing lag to:  361 seq_len is  5\n",
      "94000 [array(4.405650088301627e-06, dtype=float32), array(0.0010974289616569877, dtype=float32), array(5.458157037452338e-09, dtype=float32)]\n",
      "0.000564598594792\n",
      "[[ 5.  6.  3.  9.  6.]\n",
      " [ 5.  6.  3.  9.  6.]]\n",
      "94203 Increasing lag to:  362 seq_len is  5\n",
      "94245 Increasing lag to:  363 seq_len is  5\n",
      "94265 Increasing lag to:  364 seq_len is  5\n",
      "94315 Increasing lag to:  365 seq_len is  5\n",
      "94415 Increasing lag to:  366 seq_len is  5\n",
      "94455 Increasing lag to:  367 seq_len is  5\n",
      "94507 Increasing lag to:  368 seq_len is  5\n",
      "94536 Increasing lag to:  369 seq_len is  5\n",
      "94708 Increasing lag to:  370 seq_len is  5\n",
      "94772 Increasing lag to:  371 seq_len is  5\n",
      "94789 Increasing lag to:  372 seq_len is  5\n",
      "94824 Increasing lag to:  373 seq_len is  5\n",
      "94858 Increasing lag to:  374 seq_len is  5\n",
      "94968 Increasing lag to:  375 seq_len is  5\n",
      "94993 Increasing lag to:  376 seq_len is  5\n",
      "94994 Increasing lag to:  377 seq_len is  5\n",
      "94997 Increasing lag to:  378 seq_len is  5\n",
      "95051 Increasing lag to:  379 seq_len is  5\n",
      "95056 Increasing lag to:  380 seq_len is  5\n",
      "95097 Increasing lag to:  381 seq_len is  5\n",
      "95169 Increasing lag to:  382 seq_len is  5\n",
      "95260 Increasing lag to:  383 seq_len is  5\n",
      "95278 Increasing lag to:  384 seq_len is  5\n",
      "95283 Increasing lag to:  385 seq_len is  5\n",
      "95295 Increasing lag to:  386 seq_len is  5\n",
      "95427 Increasing lag to:  387 seq_len is  5\n",
      "95468 Increasing lag to:  388 seq_len is  5\n",
      "95577 Increasing lag to:  389 seq_len is  5\n",
      "95595 Increasing lag to:  390 seq_len is  5\n",
      "95653 Increasing lag to:  391 seq_len is  5\n",
      "95747 Increasing lag to:  392 seq_len is  5\n",
      "95774 Increasing lag to:  393 seq_len is  5\n",
      "95793 Increasing lag to:  394 seq_len is  5\n",
      "95850 Increasing lag to:  395 seq_len is  5\n",
      "95860 Increasing lag to:  396 seq_len is  5\n",
      "95877 Increasing lag to:  397 seq_len is  5\n",
      "96000 [array(5.9753925597760826e-05, dtype=float32), array(0.0011473706690594554, dtype=float32), array(2.0399922107117163e-07, dtype=float32)]\n",
      "0.000564828806091\n",
      "[[ 3.  4.  8.  7.  7.]\n",
      " [ 3.  4.  8.  7.  8.]]\n",
      "96031 Increasing lag to:  398 seq_len is  5\n",
      "96045 Increasing lag to:  399 seq_len is  5\n",
      "96055 Increasing lag to:  400 seq_len is  5\n",
      "96070 Increasing lag to:  401 seq_len is  5\n",
      "96103 Increasing lag to:  402 seq_len is  5\n",
      "96129 Increasing lag to:  403 seq_len is  5\n",
      "96190 Increasing lag to:  404 seq_len is  5\n",
      "96245 Increasing lag to:  405 seq_len is  5\n",
      "96261 Increasing lag to:  406 seq_len is  5\n",
      "96309 Increasing lag to:  407 seq_len is  5\n",
      "96326 Increasing lag to:  408 seq_len is  5\n",
      "96372 Increasing lag to:  409 seq_len is  5\n",
      "96514 Increasing lag to:  410 seq_len is  5\n",
      "96566 Increasing lag to:  411 seq_len is  5\n",
      "96698 Increasing lag to:  412 seq_len is  5\n",
      "96699 Increasing lag to:  413 seq_len is  5\n",
      "96711 Increasing lag to:  414 seq_len is  5\n",
      "96719 Increasing lag to:  415 seq_len is  5\n",
      "96789 Increasing lag to:  416 seq_len is  5\n",
      "96800 Increasing lag to:  417 seq_len is  5\n",
      "96807 Increasing lag to:  418 seq_len is  5\n",
      "96822 Increasing lag to:  419 seq_len is  5\n",
      "96838 Increasing lag to:  420 seq_len is  5\n",
      "96864 Increasing lag to:  421 seq_len is  5\n",
      "96891 Increasing lag to:  422 seq_len is  5\n",
      "96905 Increasing lag to:  423 seq_len is  5\n",
      "96913 Increasing lag to:  424 seq_len is  5\n",
      "97040 Increasing lag to:  425 seq_len is  5\n",
      "97065 Increasing lag to:  426 seq_len is  5\n",
      "97203 Increasing lag to:  427 seq_len is  5\n",
      "97215 Increasing lag to:  428 seq_len is  5\n",
      "97256 Increasing lag to:  429 seq_len is  5\n",
      "97274 Increasing lag to:  430 seq_len is  5\n",
      "97333 Increasing lag to:  431 seq_len is  5\n",
      "97343 Increasing lag to:  432 seq_len is  5\n",
      "97386 Increasing lag to:  433 seq_len is  5\n",
      "97489 Increasing lag to:  434 seq_len is  5\n",
      "97491 Increasing lag to:  435 seq_len is  5\n",
      "97546 Increasing lag to:  436 seq_len is  5\n",
      "97561 Increasing lag to:  437 seq_len is  5\n",
      "97595 Increasing lag to:  438 seq_len is  5\n",
      "97635 Increasing lag to:  439 seq_len is  5\n",
      "97686 Increasing lag to:  440 seq_len is  5\n",
      "97691 Increasing lag to:  441 seq_len is  5\n",
      "97737 Increasing lag to:  442 seq_len is  5\n",
      "97863 Increasing lag to:  443 seq_len is  5\n",
      "97977 Increasing lag to:  444 seq_len is  5\n",
      "98000 [array(0.00024769973242655396, dtype=float32), array(0.0013297840487211943, dtype=float32), array(3.3478047498647356e-06, dtype=float32)]\n",
      "0.000523452938069\n",
      "[[ 7.  6.  8.  5.  2.]\n",
      " [ 7.  6.  8.  5.  2.]]\n",
      "98042 Increasing lag to:  445 seq_len is  5\n",
      "98107 Increasing lag to:  446 seq_len is  5\n",
      "98139 Increasing lag to:  447 seq_len is  5\n",
      "98223 Increasing lag to:  448 seq_len is  5\n",
      "98247 Increasing lag to:  449 seq_len is  5\n",
      "98264 Increasing lag to:  450 seq_len is  5\n",
      "98286 Increasing lag to:  451 seq_len is  5\n",
      "98394 Increasing lag to:  452 seq_len is  5\n",
      "98414 Increasing lag to:  453 seq_len is  5\n",
      "98453 Increasing lag to:  454 seq_len is  5\n",
      "98461 Increasing lag to:  455 seq_len is  5\n",
      "98497 Increasing lag to:  456 seq_len is  5\n",
      "98507 Increasing lag to:  457 seq_len is  5\n",
      "98508 Increasing lag to:  458 seq_len is  5\n",
      "98535 Increasing lag to:  459 seq_len is  5\n",
      "98581 Increasing lag to:  460 seq_len is  5\n",
      "98694 Increasing lag to:  461 seq_len is  5\n",
      "98700 Increasing lag to:  462 seq_len is  5\n",
      "98714 Increasing lag to:  463 seq_len is  5\n",
      "98720 Increasing lag to:  464 seq_len is  5\n",
      "98735 Increasing lag to:  465 seq_len is  5\n",
      "98739 Increasing lag to:  466 seq_len is  5\n",
      "98761 Increasing lag to:  467 seq_len is  5\n",
      "98845 Increasing lag to:  468 seq_len is  5\n",
      "98887 Increasing lag to:  469 seq_len is  5\n",
      "98897 Increasing lag to:  470 seq_len is  5\n",
      "98916 Increasing lag to:  471 seq_len is  5\n",
      "98994 Increasing lag to:  472 seq_len is  5\n",
      "99043 Increasing lag to:  473 seq_len is  5\n",
      "99064 Increasing lag to:  474 seq_len is  5\n",
      "99093 Increasing lag to:  475 seq_len is  5\n",
      "99137 Increasing lag to:  476 seq_len is  5\n",
      "99180 Increasing lag to:  477 seq_len is  5\n",
      "99209 Increasing lag to:  478 seq_len is  5\n",
      "99222 Increasing lag to:  479 seq_len is  5\n",
      "99291 Increasing lag to:  480 seq_len is  5\n",
      "99437 Increasing lag to:  481 seq_len is  5\n",
      "99531 Increasing lag to:  482 seq_len is  5\n",
      "99565 Increasing lag to:  483 seq_len is  5\n",
      "99649 Increasing lag to:  484 seq_len is  5\n",
      "99686 Increasing lag to:  485 seq_len is  5\n",
      "99711 Increasing lag to:  486 seq_len is  5\n",
      "99715 Increasing lag to:  487 seq_len is  5\n",
      "99795 Increasing lag to:  488 seq_len is  5\n",
      "99819 Increasing lag to:  489 seq_len is  5\n",
      "99820 Increasing lag to:  490 seq_len is  5\n",
      "99876 Increasing lag to:  491 seq_len is  5\n",
      "100000 [array(0.00010717008262872696, dtype=float32), array(0.0011838318314403296, dtype=float32), array(1.6616281754977535e-06, dtype=float32)]\n",
      "0.000693403766491\n",
      "[[ 3.  4.  4.  3.  3.]\n",
      " [ 3.  4.  4.  3.  4.]]\n",
      "100032 Increasing lag to:  492 seq_len is  5\n",
      "100111 Increasing lag to:  493 seq_len is  5\n",
      "100193 Increasing lag to:  494 seq_len is  5\n",
      "100247 Increasing lag to:  495 seq_len is  5\n",
      "100279 Increasing lag to:  496 seq_len is  5\n",
      "100415 Increasing lag to:  497 seq_len is  5\n",
      "100423 Increasing lag to:  498 seq_len is  5\n",
      "100424 Increasing lag to:  499 seq_len is  5\n",
      "100458 Increasing lag to:  500 seq_len is  5\n",
      "100510 Increasing lag to:  500 seq_len is  5\n",
      "100605 Increasing lag to:  500 seq_len is  5\n",
      "100609 Increasing lag to:  500 seq_len is  5\n",
      "100683 Increasing lag to:  500 seq_len is  5\n",
      "100731 Increasing lag to:  500 seq_len is  5\n",
      "100734 Increasing lag to:  500 seq_len is  5\n",
      "100736 Increasing lag to:  500 seq_len is  5\n",
      "100740 Increasing lag to:  500 seq_len is  5\n",
      "100753 Increasing lag to:  500 seq_len is  5\n",
      "100787 Increasing lag to:  500 seq_len is  5\n",
      "101018 Increasing lag to:  500 seq_len is  5\n",
      "101021 Increasing lag to:  500 seq_len is  5\n",
      "101073 Increasing lag to:  500 seq_len is  5\n",
      "101113 Increasing lag to:  500 seq_len is  5\n",
      "101162 Increasing lag to:  500 seq_len is  5\n",
      "101209 Increasing lag to:  500 seq_len is  5\n",
      "101211 Increasing lag to:  500 seq_len is  5\n",
      "101290 Increasing lag to:  500 seq_len is  5\n",
      "101363 Increasing lag to:  500 seq_len is  5\n",
      "101375 Increasing lag to:  500 seq_len is  5\n",
      "101536 Increasing lag to:  500 seq_len is  5\n",
      "101577 Increasing lag to:  500 seq_len is  5\n",
      "101754 Increasing lag to:  500 seq_len is  5\n",
      "101759 Increasing lag to:  500 seq_len is  5\n",
      "101773 Increasing lag to:  500 seq_len is  5\n",
      "101807 Increasing lag to:  500 seq_len is  5\n",
      "101823 Increasing lag to:  500 seq_len is  5\n",
      "101835 Increasing lag to:  500 seq_len is  5\n",
      "101853 Increasing lag to:  500 seq_len is  5\n",
      "101871 Increasing lag to:  500 seq_len is  5\n",
      "101930 Increasing lag to:  500 seq_len is  5\n",
      "101950 Increasing lag to:  500 seq_len is  5\n",
      "101982 Increasing lag to:  500 seq_len is  5\n",
      "102000 [array(0.00015450941282324493, dtype=float32), array(0.0012249874416738749, dtype=float32), array(7.722925943198788e-07, dtype=float32)]\n",
      "0.000676371622831\n",
      "[[ 9.  6.  6.  2.  3.]\n",
      " [ 9.  6.  6.  2.  3.]]\n",
      "102158 Increasing lag to:  500 seq_len is  5\n",
      "102165 Increasing lag to:  500 seq_len is  5\n",
      "102230 Increasing lag to:  500 seq_len is  5\n",
      "102286 Increasing lag to:  500 seq_len is  5\n",
      "102309 Increasing lag to:  500 seq_len is  5\n",
      "102475 Increasing lag to:  500 seq_len is  5\n",
      "102488 Increasing lag to:  500 seq_len is  5\n",
      "102491 Increasing lag to:  500 seq_len is  5\n",
      "102594 Increasing lag to:  500 seq_len is  5\n",
      "102643 Increasing lag to:  500 seq_len is  5\n",
      "102684 Increasing lag to:  500 seq_len is  5\n",
      "102697 Increasing lag to:  500 seq_len is  5\n",
      "102858 Increasing lag to:  500 seq_len is  5\n",
      "102911 Increasing lag to:  500 seq_len is  5\n",
      "102981 Increasing lag to:  500 seq_len is  5\n",
      "103021 Increasing lag to:  500 seq_len is  5\n",
      "103060 Increasing lag to:  500 seq_len is  5\n",
      "103276 Increasing lag to:  500 seq_len is  5\n",
      "103281 Increasing lag to:  500 seq_len is  5\n",
      "103291 Increasing lag to:  500 seq_len is  5\n",
      "103352 Increasing lag to:  500 seq_len is  5\n",
      "103384 Increasing lag to:  500 seq_len is  5\n",
      "103415 Increasing lag to:  500 seq_len is  5\n",
      "103471 Increasing lag to:  500 seq_len is  5\n",
      "103507 Increasing lag to:  500 seq_len is  5\n",
      "103685 Increasing lag to:  500 seq_len is  5\n",
      "103751 Increasing lag to:  500 seq_len is  5\n",
      "103766 Increasing lag to:  500 seq_len is  5\n",
      "103768 Increasing lag to:  500 seq_len is  5\n",
      "103816 Increasing lag to:  500 seq_len is  5\n",
      "103867 Increasing lag to:  500 seq_len is  5\n",
      "103869 Increasing lag to:  500 seq_len is  5\n",
      "103969 Increasing lag to:  500 seq_len is  5\n",
      "104000 [array(9.299857083533425e-06, dtype=float32), array(0.0010731506627053022, dtype=float32), array(6.461625456921638e-09, dtype=float32)]\n",
      "0.000560636457521\n",
      "[[ 9.  3.  7.  8.  9.]\n",
      " [ 9.  3.  7.  8.  7.]]\n",
      "104012 Increasing lag to:  500 seq_len is  5\n",
      "104190 Increasing lag to:  500 seq_len is  5\n",
      "104193 Increasing lag to:  500 seq_len is  5\n",
      "104210 Increasing lag to:  500 seq_len is  5\n",
      "104227 Increasing lag to:  500 seq_len is  5\n",
      "104257 Increasing lag to:  500 seq_len is  5\n",
      "104314 Increasing lag to:  500 seq_len is  5\n",
      "104440 Increasing lag to:  500 seq_len is  5\n",
      "104454 Increasing lag to:  500 seq_len is  5\n",
      "104494 Increasing lag to:  500 seq_len is  5\n",
      "104519 Increasing lag to:  500 seq_len is  5\n",
      "104554 Increasing lag to:  500 seq_len is  5\n",
      "104618 Increasing lag to:  500 seq_len is  5\n",
      "104746 Increasing lag to:  500 seq_len is  5\n",
      "104783 Increasing lag to:  500 seq_len is  5\n",
      "104882 Increasing lag to:  500 seq_len is  5\n",
      "104890 Increasing lag to:  500 seq_len is  5\n",
      "104959 Increasing lag to:  500 seq_len is  5\n",
      "105049 Increasing lag to:  500 seq_len is  5\n",
      "105110 Increasing lag to:  500 seq_len is  5\n",
      "105158 Increasing lag to:  500 seq_len is  5\n",
      "105171 Increasing lag to:  500 seq_len is  5\n",
      "105189 Increasing lag to:  500 seq_len is  5\n",
      "105194 Increasing lag to:  500 seq_len is  5\n",
      "105195 Increasing lag to:  500 seq_len is  5\n",
      "105198 Increasing lag to:  500 seq_len is  5\n",
      "105202 Increasing lag to:  500 seq_len is  5\n",
      "105203 Increasing lag to:  500 seq_len is  5\n",
      "105224 Increasing lag to:  500 seq_len is  5\n",
      "105292 Increasing lag to:  500 seq_len is  5\n",
      "105309 Increasing lag to:  500 seq_len is  5\n",
      "105401 Increasing lag to:  500 seq_len is  5\n",
      "105441 Increasing lag to:  500 seq_len is  5\n",
      "105570 Increasing lag to:  500 seq_len is  5\n",
      "105602 Increasing lag to:  500 seq_len is  5\n",
      "105611 Increasing lag to:  500 seq_len is  5\n",
      "105821 Increasing lag to:  500 seq_len is  5\n",
      "105836 Increasing lag to:  500 seq_len is  5\n",
      "105863 Increasing lag to:  500 seq_len is  5\n",
      "105892 Increasing lag to:  500 seq_len is  5\n",
      "105975 Increasing lag to:  500 seq_len is  5\n",
      "105976 Increasing lag to:  500 seq_len is  5\n",
      "106000 [array(4.055659701407421e-06, dtype=float32), array(0.0010615736246109009, dtype=float32), array(4.465558145483328e-09, dtype=float32)]\n",
      "0.000492374529131\n",
      "[[ 9.  7.  8.  8.  9.]\n",
      " [ 9.  7.  8.  8.  8.]]\n",
      "106016 Increasing lag to:  500 seq_len is  5\n",
      "106080 Increasing lag to:  500 seq_len is  5\n",
      "106200 Increasing lag to:  500 seq_len is  5\n",
      "106223 Increasing lag to:  500 seq_len is  5\n",
      "106270 Increasing lag to:  500 seq_len is  5\n",
      "106279 Increasing lag to:  500 seq_len is  5\n",
      "106395 Increasing lag to:  500 seq_len is  5\n",
      "106424 Increasing lag to:  500 seq_len is  5\n",
      "106493 Increasing lag to:  500 seq_len is  5\n",
      "106519 Increasing lag to:  500 seq_len is  5\n",
      "106533 Increasing lag to:  500 seq_len is  5\n",
      "106543 Increasing lag to:  500 seq_len is  5\n",
      "106659 Increasing lag to:  500 seq_len is  5\n",
      "106694 Increasing lag to:  500 seq_len is  5\n",
      "106747 Increasing lag to:  500 seq_len is  5\n",
      "106761 Increasing lag to:  500 seq_len is  5\n",
      "106904 Increasing lag to:  500 seq_len is  5\n",
      "107029 Increasing lag to:  500 seq_len is  5\n",
      "107056 Increasing lag to:  500 seq_len is  5\n",
      "107094 Increasing lag to:  500 seq_len is  5\n",
      "107304 Increasing lag to:  500 seq_len is  5\n",
      "107380 Increasing lag to:  500 seq_len is  5\n",
      "107405 Increasing lag to:  500 seq_len is  5\n",
      "107444 Increasing lag to:  500 seq_len is  5\n",
      "107452 Increasing lag to:  500 seq_len is  5\n",
      "107525 Increasing lag to:  500 seq_len is  5\n",
      "107567 Increasing lag to:  500 seq_len is  5\n",
      "107590 Increasing lag to:  500 seq_len is  5\n",
      "107607 Increasing lag to:  500 seq_len is  5\n",
      "107624 Increasing lag to:  500 seq_len is  5\n",
      "107639 Increasing lag to:  500 seq_len is  5\n",
      "107644 Increasing lag to:  500 seq_len is  5\n",
      "107662 Increasing lag to:  500 seq_len is  5\n",
      "107689 Increasing lag to:  500 seq_len is  5\n",
      "107773 Increasing lag to:  500 seq_len is  5\n",
      "107832 Increasing lag to:  500 seq_len is  5\n",
      "107905 Increasing lag to:  500 seq_len is  5\n",
      "107906 Increasing lag to:  500 seq_len is  5\n",
      "107930 Increasing lag to:  500 seq_len is  5\n",
      "108000 [array(6.626114918617532e-05, dtype=float32), array(0.0011172896483913064, dtype=float32), array(1.364608976928139e-07, dtype=float32)]\n",
      "0.00047931811423\n",
      "[[ 4.  9.  3.  9.  7.]\n",
      " [ 4.  9.  3.  9.  7.]]\n",
      "108014 Increasing lag to:  500 seq_len is  5\n",
      "108042 Increasing lag to:  500 seq_len is  5\n",
      "108143 Increasing lag to:  500 seq_len is  5\n",
      "108151 Increasing lag to:  500 seq_len is  5\n",
      "108219 Increasing lag to:  500 seq_len is  5\n",
      "108222 Increasing lag to:  500 seq_len is  5\n",
      "108341 Increasing lag to:  500 seq_len is  5\n",
      "108548 Increasing lag to:  500 seq_len is  5\n",
      "108573 Increasing lag to:  500 seq_len is  5\n",
      "108610 Increasing lag to:  500 seq_len is  5\n",
      "108645 Increasing lag to:  500 seq_len is  5\n",
      "108712 Increasing lag to:  500 seq_len is  5\n",
      "108781 Increasing lag to:  500 seq_len is  5\n",
      "108788 Increasing lag to:  500 seq_len is  5\n",
      "108817 Increasing lag to:  500 seq_len is  5\n",
      "109067 Increasing lag to:  500 seq_len is  5\n",
      "109085 Increasing lag to:  500 seq_len is  5\n",
      "109131 Increasing lag to:  500 seq_len is  5\n",
      "109135 Increasing lag to:  500 seq_len is  5\n",
      "109151 Increasing lag to:  500 seq_len is  5\n",
      "109223 Increasing lag to:  500 seq_len is  5\n",
      "109324 Increasing lag to:  500 seq_len is  5\n",
      "109345 Increasing lag to:  500 seq_len is  5\n",
      "109361 Increasing lag to:  500 seq_len is  5\n",
      "109389 Increasing lag to:  500 seq_len is  5\n",
      "109488 Increasing lag to:  500 seq_len is  5\n",
      "109602 Increasing lag to:  500 seq_len is  5\n",
      "109661 Increasing lag to:  500 seq_len is  5\n",
      "109747 Increasing lag to:  500 seq_len is  5\n",
      "109840 Increasing lag to:  500 seq_len is  5\n",
      "109885 Increasing lag to:  500 seq_len is  5\n",
      "109917 Increasing lag to:  500 seq_len is  5\n",
      "109993 Increasing lag to:  500 seq_len is  5\n",
      "110000 [array(3.514537411319907e-06, dtype=float32), array(0.0010479523334652185, dtype=float32), array(4.961069777209559e-09, dtype=float32)]\n",
      "0.000590298208408\n",
      "[[ 6.  8.  7.  2.  3.]\n",
      " [ 6.  8.  7.  2.  3.]]\n",
      "110093 Increasing lag to:  500 seq_len is  5\n",
      "110138 Increasing lag to:  500 seq_len is  5\n",
      "110252 Increasing lag to:  500 seq_len is  5\n",
      "110276 Increasing lag to:  500 seq_len is  5\n",
      "110316 Increasing lag to:  500 seq_len is  5\n",
      "110345 Increasing lag to:  500 seq_len is  5\n",
      "110395 Increasing lag to:  500 seq_len is  5\n",
      "110442 Increasing lag to:  500 seq_len is  5\n",
      "110450 Increasing lag to:  500 seq_len is  5\n",
      "110489 Increasing lag to:  500 seq_len is  5\n",
      "110491 Increasing lag to:  500 seq_len is  5\n",
      "110540 Increasing lag to:  500 seq_len is  5\n",
      "110547 Increasing lag to:  500 seq_len is  5\n",
      "110633 Increasing lag to:  500 seq_len is  5\n",
      "110720 Increasing lag to:  500 seq_len is  5\n",
      "110734 Increasing lag to:  500 seq_len is  5\n",
      "110736 Increasing lag to:  500 seq_len is  5\n",
      "110738 Increasing lag to:  500 seq_len is  5\n",
      "110755 Increasing lag to:  500 seq_len is  5\n",
      "110759 Increasing lag to:  500 seq_len is  5\n",
      "110847 Increasing lag to:  500 seq_len is  5\n",
      "110869 Increasing lag to:  500 seq_len is  5\n",
      "110947 Increasing lag to:  500 seq_len is  5\n",
      "110971 Increasing lag to:  500 seq_len is  5\n",
      "111024 Increasing lag to:  500 seq_len is  5\n",
      "111245 Increasing lag to:  500 seq_len is  5\n",
      "111286 Increasing lag to:  500 seq_len is  5\n",
      "111331 Increasing lag to:  500 seq_len is  5\n",
      "111401 Increasing lag to:  500 seq_len is  5\n",
      "111423 Increasing lag to:  500 seq_len is  5\n",
      "111442 Increasing lag to:  500 seq_len is  5\n",
      "111456 Increasing lag to:  500 seq_len is  5\n",
      "111531 Increasing lag to:  500 seq_len is  5\n",
      "111533 Increasing lag to:  500 seq_len is  5\n",
      "111554 Increasing lag to:  500 seq_len is  5\n",
      "111602 Increasing lag to:  500 seq_len is  5\n",
      "111610 Increasing lag to:  500 seq_len is  5\n",
      "111714 Increasing lag to:  500 seq_len is  5\n",
      "111718 Increasing lag to:  500 seq_len is  5\n",
      "111726 Increasing lag to:  500 seq_len is  5\n",
      "111935 Increasing lag to:  500 seq_len is  5\n",
      "112000 [array(0.00018759586964733899, dtype=float32), array(0.00122579257003963, dtype=float32), array(2.0952005797880702e-05, dtype=float32)]\n",
      "0.000618222053163\n",
      "[[ 8.  7.  4.  2.  4.]\n",
      " [ 8.  7.  4.  2.  4.]]\n",
      "112084 Increasing lag to:  500 seq_len is  5\n",
      "112118 Increasing lag to:  500 seq_len is  5\n",
      "112123 Increasing lag to:  500 seq_len is  5\n",
      "112128 Increasing lag to:  500 seq_len is  5\n",
      "112148 Increasing lag to:  500 seq_len is  5\n",
      "112183 Increasing lag to:  500 seq_len is  5\n",
      "112372 Increasing lag to:  500 seq_len is  5\n",
      "112433 Increasing lag to:  500 seq_len is  5\n",
      "112475 Increasing lag to:  500 seq_len is  5\n",
      "112524 Increasing lag to:  500 seq_len is  5\n",
      "112547 Increasing lag to:  500 seq_len is  5\n",
      "112607 Increasing lag to:  500 seq_len is  5\n",
      "112708 Increasing lag to:  500 seq_len is  5\n",
      "112802 Increasing lag to:  500 seq_len is  5\n",
      "112939 Increasing lag to:  500 seq_len is  5\n",
      "112947 Increasing lag to:  500 seq_len is  5\n",
      "112970 Increasing lag to:  500 seq_len is  5\n",
      "113081 Increasing lag to:  500 seq_len is  5\n",
      "113118 Increasing lag to:  500 seq_len is  5\n",
      "113263 Increasing lag to:  500 seq_len is  5\n",
      "113285 Increasing lag to:  500 seq_len is  5\n",
      "113323 Increasing lag to:  500 seq_len is  5\n",
      "113387 Increasing lag to:  500 seq_len is  5\n",
      "113399 Increasing lag to:  500 seq_len is  5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-cedc21612a74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# You can set the batch size here (or leave 32, which seems reasonable)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mXc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_copy_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis_lag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthis_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy_trainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# If the results are good enough, increase the length.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/pio/os/anaconda/lib/python2.7/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/pio/os/anaconda/lib/python2.7/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    670\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0;32m    671\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m--> 672\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/pio/os/anaconda/lib/python2.7/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    659\u001b[0m                         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m                         self, node)\n\u001b[0m\u001b[0;32m    662\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mscan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/tmp/i264573/theano.NOBACKUP/compiledir_Linux-3.13--generic-x86_64-with-debian-jessie-sid-x86_64-2.7.10-64/scan_perform/mod.cpp:4585)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/pio/os/anaconda/lib/python2.7/site-packages/theano/tensor/type.py\u001b[0m in \u001b[0;36mvalue_zeros\u001b[1;34m(self, shape)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mvalue_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         \"\"\"\n\u001b[0;32m    581\u001b[0m         \u001b[0mCreate\u001b[0m \u001b[0man\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mof\u001b[0m \u001b[1;36m0\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "copy_net.initialize()\n",
    "\n",
    "# Feel free to tune the learing rate, this one worked the best for me. \n",
    "# We don't use any learing scheuling (lrate is constant), as every time the net starts getting closer to optimum, \n",
    "# we just make the problem harder (increasse the time lag) instead of trying to find the optimum more accurately\n",
    "# I tried using learing rate scheduling, without any noticable iprovement\n",
    "\n",
    "lrate = 5e-3\n",
    "copy_trainer.lrate.set_value(lrate)\n",
    "\n",
    "# Set weight decay, it seems to be helpful\n",
    "copy_trainer.wdec.set_value(1e-6)\n",
    "\n",
    "losses = []\n",
    "\n",
    "# Set the sequence parameters. We start from a trivial task and make it more difficult as we make progress.\n",
    "\n",
    "lag0 = 4\n",
    "lag = lag0\n",
    "seq_len0 = 1\n",
    "seq_len = seq_len0\n",
    "max_seq_len = 5 # Note that you may need more neurons for a longer sequence\n",
    "max_lag = 500\n",
    "\n",
    "for i in xrange(400000):\n",
    "    # lrate = \n",
    "    # copy_trainer.lrate.set_value(lrate)\n",
    "    \n",
    "    # We don't want the network to forget a solution for shorter sequences, so the sampled example is of a random size.\n",
    "    # This seems to be important for generalization.\n",
    "    this_lag = randint(lag0, lag + 1)\n",
    "    this_len = randint(seq_len0, seq_len + 1)\n",
    "    \n",
    "    # You can set the batch size here (or leave 32, which seems reasonable)\n",
    "    Xc, Yc = gen_copy_example(this_lag, this_len, 32)\n",
    "    ret = copy_trainer.train_function(Xc, Yc)\n",
    "    \n",
    "    # If the results are good enough, increase the length. \n",
    "    if this_lag > 0.9 * lag and this_len == seq_len and ret[0] < 3e-3:\n",
    "        lag += 1\n",
    "        seq_len = min(max_seq_len, lag / 10 + 1)\n",
    "        lag = min(lag, max_lag)\n",
    "        print i, \"Increasing lag to: \", lag , \"seq_len is \", seq_len\n",
    "    if i%2000 == 0:\n",
    "        print i, ret\n",
    "        Xc, Yc = gen_copy_example(lag, seq_len, 32)\n",
    "        ret = copy_test_function(Xc, Yc)\n",
    "        print ret\n",
    "        if i != 0: #ignore noisy start\n",
    "            losses.append((i,) + tuple([ret, lag]))\n",
    "        decoded_input = decode_matrix(Xc)\n",
    "        decoded_output = decode_matrix(copy_check_output(Xc).reshape(Xc.shape))\n",
    "        \n",
    "        # Sanity check\n",
    "        # Note that here we check the net's beahaviour on the max test, whereas most of training examples are shorter.\n",
    "        # We trust that the net outputs T + n '0's at the start, so we don't print it here for the transparency\n",
    "        print vstack([decoded_input[:,0].ravel()[:seq_len], decoded_output[:,0].ravel()[-seq_len:]])\n",
    "\n",
    "        \n",
    "# print charts\n",
    "\n",
    "losses_a = np.array(losses)\n",
    "\n",
    "p1 = plt.figure(1)\n",
    "\n",
    "legend(loc='lower right')\n",
    "title('Training loss')\n",
    "xlabel('iteration')\n",
    "\n",
    "plot(losses_a[:,0], losses_a[:,1], label='rms')\n",
    "\n",
    "savefig('losses_small.png')\n",
    "p1.show()\n",
    "\n",
    "#semilogy(losses_a[:,0], losses_a[:,2], label='rms + wdec')\n",
    "#semilogy(losses_a[:,0], losses_a[:,2], label='rms')\n",
    "#plot(losses_a[:,0], losses_a[:,3], label='grad norm')\n",
    "\n",
    "p2 = plt.figure(2)\n",
    "\n",
    "plot(losses_a[:,0], losses_a[:,2], label='lag')\n",
    "\n",
    "legend(loc='lower right')\n",
    "title('Lag')\n",
    "xlabel('iteration')\n",
    "\n",
    "savefig('lag_small.png')\n",
    "p2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the very rapid decrease in the loss as the lag gets bigger. This is mostly caused by the fact that the loss is the average loss over the whole genereted sequence, so the loss is sum_of_losses/length. The length increases, but sum_of_losses stays more or less the same, as the network is still rather confident that it should output '0's before seeing a '1' on the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's wee what the trained network can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000236255436903\n",
      "[[ 4.  7.  6.  7.  6.]\n",
      " [ 4.  7.  6.  7.  6.]]\n",
      "[[ 4.  0.]\n",
      " [ 7.  0.]\n",
      " [ 6.  0.]\n",
      " ..., \n",
      " [ 0.  6.]\n",
      " [ 0.  7.]\n",
      " [ 0.  6.]]\n"
     ]
    }
   ],
   "source": [
    "lag = 500\n",
    "seq_len = 5\n",
    "Xc, Yc = gen_copy_example(lag, seq_len, 1)\n",
    "ret = copy_test_function(Xc, Yc)\n",
    "decoded_input = decode_matrix(Xc)\n",
    "decoded_output = decode_matrix(copy_check_output(Xc).reshape(Xc.shape))\n",
    "print ret\n",
    "print vstack([decoded_input.ravel()[:seq_len], decoded_output.ravel()[-seq_len:]])\n",
    "print hstack([decoded_input, decoded_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
